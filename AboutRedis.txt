Redis特性
1.速度快
	数据存在哪?
	数据存在了内存条
	什么语言写?
	用的是C语言
	线程模型?
	单线程
2.持久化
	Redis所有数据保存在内存中,对数据的更新将异步地保存到磁盘上
3.多种数据结构
	字符串
		重要API:get	set	del	O(1)
			incr(自增1) decr(自减1) O(1)
			incrby(incrby key k,key自增加k,如果key不存在,自增后get(key) = k) O(1)
			decrby(decrby key k, key自减k,如果key不存在,自减后get(key)=-k) O(1)
			mget mset 批量操作字符串O(n)
	哈希
		value中的key不能相同 value中的value可以相同
		重要API:hget hset hdel O(1)
				hexists (hexists key field 判断hash key 是否有field)
				hlen (hlen key 获取hash key field的数量)
				hmget hmset 批量操作哈希 O(n)
				hgetall (hgetall key 返回hash对应所有的field和value) O(n)
				hvals (hvals key 返回hash key对应所有field的value) O(n)
				hkeys (hkeys key 返回hash key对应所有field) O(n)
	列表
		特点:有序 可以重复
		重要API:rpush 从右边开始插入 O(1)
				lpush 从左边开始插入 O(1)
				linsert (linsert key before|after value newValue 在list指定的前|后插入newValue) O(n)
				lpop 从左边弹出一个元素 O(1)
				rpop 从右边弹出一个元素 O(1)
				lrem (lrem key count value 根据count值 从列表中删除所有value相等的项)
					(1)count>0 从左到右 删除最多count个value相等的项
					(2)count<0 从右到左 删除最多count个value相等的项
					(3)count=0 删除所有等于value的项
				ltrim (ltrim key start end 按照索引范围修剪列表)
				lrange (lrange key start end 获取列表指定范围内所有item 注意这里包含end)
				lindex (lindex key index 按照列表索引获取item)
				llen (llen key 获取列表的长度) O(1)
				lset (lset key index newValue 设置列表指定索引值为newValue)
	集合
		特点:无序(不能通过索引或下标来操作 存的value值为element) 无重复 可以进行集合间操作
		重要API:sadd (sadd key element 向集合key添加新的element，如果element已经存在 则添加失败)
				srem (srem key element 将集合key中的element移除掉)
				scard 计算集合大小
				sismember 判断element是否存在集合中
				srandmember 从集合中随机挑选一个element
				spop 从集合中随机弹出一个element(区别于上面的srandmember,spop弹出element之后,element就不存在于集合中)
				smembers 取出集合中的所有element(无序 O(n)小心使用)
				sdiff 计算差集
				sinter 计算交集
				sunion 计算并集
				sdiff|sinter|sunion store destkey (将差集/交集/并集结果保存在destkey中)
	有序集合
		特点:有序(存的value值为 score+element) 无重复(score可以重复 element不可以重复)
		重要API:zadd (zadd key score element 添加score和element)
				zrem (zrem key emelent 删除element)
				zscore (zscore key element 返回emelent的score)
				zincrby (zincrby key score element 增加或减少element的score)
				zcard 返回集合中的element个数
				zrank 获取element的排名
				zcount (zcount key minScore maxScore 返回有序集合内在指定分数范围内的个数)
				zdiffstore 计算差集
				zinterstore 计算交集
				zunionstore 计算并集
4.支持多种客户端语言
5.功能丰富
	发布订阅
	支持lua脚本
	支持事务
	支持pipeline
6."简单"
7.主从复制
8.高可用,分布式
	高可用(Redis-Sentinel)
	分布式(Redis-Cluster)
	
Redsi典型应用场景
1.缓存系统
2.计数器
3.消息队列系统
4.排行榜
5.社交网络
6.实时系统

Redis常用配置
1.daemonize(是否守护进程)
默认是no,建议设置为yes，启动日志会写到日志文件中
2.port
端口号,默认端口号是6379
3.logfile
日志名
4.dir
Redis工作目录,例如日志文件,持久化文件报错到该目录中

Redis启动方式
建议使用redis的配置文件启动
window下:
1.进入redis目录
2.创建一个config文件夹
3.复制redis.windows.conf 到config目录下 修改名为redis-6379.conf (因为实际生产中 一台服务器可能启动多个redis服务器)
3.按上面常用配置参数进行相应修改
4.返回redis目录 创建data目录 存放日志等信息
5.新建6379.log文件
7.启动redis服务端:redis-server.exe config/redis-6379.conf (启动完成之后去日志文件下查看启动日志 不会再像直接启动的时候将日志输入cli在控制台了)

Redis通用命令
1.keys (计算redis中所有的key)
keys * 
时间复杂度为O(n) redis是单线程 生产环境不能随便用这个命令 扫描所有的key可以使用scan命令
2.dbsize (计算redis中所有key的大小)
时间复杂度为O(1) redis内置一个计数器 会返回所有key的个数
3.exists key (判断一个key是否存在)
时间复杂度为O(1)
4.del key (删除key)
时间复杂度为O(1) 成功删除返回1 删除失败比如key不存在返回0
5.expire key (设置key的过期时间)
时间复杂度为O(1)
ttl key (查看key还有多长时间过期) -2代表key已经不存在 -1代表key存在并且没有过期时间
presist (去除key的过期时间)
6.type key (查看key的数据类型)
时间复杂度为O(1)

Redis其它功能
1.慢查询
	生命周期:
	1.客户端发送命令
	2.Redis等待执行(单线程)
	3.执行命令
	4.返回结果
	慢查询发生在第3阶段(列如keys *)
	客户端超时不一定是慢查询,但慢查询是客户端超时的一个可能
2.pipline(流水线)
	将一批命令进行打包发送到服务端,服务端批量解决之后再按顺序返回给客户端
	使用pipline,减少了客户端发送命令到服务端以及服务端发送结果到客户端的一个时间(减少了网络时间)
	例如for循环使用中执行多次redis命令,效率就不如将这些命令打包使用pipline效率来的高
	注意:pipline每次只能作用在一个redis节点上,pipline区别于原生M操作不是原子的,但是返回的顺序是原子的
3.发布订阅
	角色:发布者(publisher)
		 订阅者(subscriber)
		 频道(channel)
	发布者(cli客户端)发送一个hello命令,通过服务端(channel)转发到订阅者(cli客户端)
	注意:一个新的订阅者是再订阅一个频道之后,它是收不到之前频道发布的消息,这里不能做一个消息的堆积,开发中要注意这种场景
	常用API：publish channel message(发布一条订阅消息)
			 subscribe [channel](订阅一个或多个频道)
			 unsubscribe [channel](取消一个或多个订阅频道)
	发布订阅和消息队列的区别:发布订阅是发布一条消息,所有订阅者都可以收到;消息队列是发布一条消息,订阅者去抢这条消息,只有一个订阅者可以收到(例如抢红包)		 
4.Bitmap(位图)
	redis是可以直接操作位数
	setbit key offset value(给位图指定索引设置值
	getbit key offset(获取位图指定索引的值)
	bigcount key [start end](获取位图指定范围start到end,单位为字节,如果不指定就是获取全部位值为1的个数)
5.HyperLogLog
	常用API:pfadd key element(向HyperLogLog添加元素)
			pfcount key(计算HyperLogLog的独立总数)
			pfmerge destkey sourcekey(合并多个HyperLogLog)
	做独立用户数的统计,注意:HyperLogLog是有错误率的,错误率为0.81%;HyperLogLog是不能取出单条数据的		
6.GEO(地理信息定位)
	存储经纬度,计算两地距离,范围计算等
	常用API:geoadd key longitude latitude member(增加地理位置信息)
			geopos key member(获取地理位置信息)
			geodist key member1,member2(获取两个地理位置的距离)

Redis持久化
redis所有数据保存在内存中,对数据的更新将异步地保存到磁盘上(如果机器或者进程崩掉,没有保存到磁盘上,数据就会丢失)
持久化方式:1.快照(mysql dump;redis RDB)
		   2.写日志(mysql binlog;Hbase Hlog;redis AOF)
RDB
1.什么是RDB
	redis创建一个RDB文件(二进制),将数据保存在硬盘上;在需要载入的时候,在把这个RDB文件载入到内存
	(也是一个复制的媒介,在主从复制之中也是用的这种方法)
2.触发机制-主要三种方式
	1.save(同步)
	如果数据量比较大,就会造成阻塞;如存在老的RDB文件,新的会替换老的;时间复杂度为O(n)
	2.bgsave(异步)
	如存在老的RDB文件,新的会替换老的;时间复杂度为O(n)
	save和bgsave比较
		IO类型:save同步;bgsave异步
		是否阻塞:save阻塞;bgsave也会阻塞,不过是发生在创建子进程fork命令中
		优点:save不会消耗额外内存;bgsave不阻塞客户端命令
		缺点:save阻塞客户端命令;bgsave需要fork,消耗内存
	3.自动
	配置文件中配置条件,当任一条件被满足的时候,自动使用bgsave命令来生成RDB文件
3.触发机制-不容忽略方式
	1.全量复制(主从复制时,主会自动生成RDB文件)
	2.debug reload
	3.shutdown
AOF
1.RDB现存问题
	1.耗时 耗性能
		O(n)数据:耗时
		fork():消耗内存
		Disk I/O:I/O消耗内存
	2.不可控 容易丢失数据(不能确定什么时候宕机)
2.什么是AOF
	当客户端运行写命令时,会在AOF日志中追加一条命令
3.AOF三种策略
	1.always(每条命令都写到硬盘中;I/O开销非常大)
	2.everysec(每秒;可能会丢失1s数据)
	3.no(根据操作系统决定;不用管;不可控)
4.AOF重写
	把一些重复的,过期的,没有用的,以及一些可优化的命令进行化简成一个很小的AOF文件
	1.减少硬盘占用量
	2.加快恢复速度
	AOF重写的两种实现方式
		1.bgwriteaof
		2.AOF重写配置
			配置名:auto-aof-rewrite-min-size	含义:AOF文件重写需要的尺寸
			配置名:auto-aof-rewrite-percentage	含义:AOF文件增长率
			统计名:aof-current-size				含义:AOF当前尺寸(单位为字节)
			统计名:aof-base-size				含义:AOF上次启动和重写的尺寸(单位为字节)
			参数:appendonly yes(打开AOF功能)
				 appendfilename "appendonly-${port}.aof"(AOF文件名)
				 appendfsync everysec(AOF同步的策略)
				 no-appendfsync-on-rewrite yes(在重写的时候,是否做AOF的append操作;为了考虑性能,这里选择重写的时候,不能做AOF的append操作)
				 auto-aof-rewrite-percentage 100
				 auto-aof-rewrite-min-size 64mb
RDB与AOF
	命令		RDB			AOF
	启动优先级	低			高		假如工作目录下既有RDB也有AOF,在服务器挂机重启后,会优先加载AOF
	体积		小			大
	恢复速度	快照		慢
	数据安全性	丢数据		根据策略决定
	轻重		重			轻
	RDB最佳策略		"关"	集中管理
	AOF最佳策略		"开":缓存和存储		AOF重写集中管理
	
Redis复制的原理与优化
1.什么是主从复制
	进行一个数据的备份,避免机器宕机等带来的问题;可以进行一个流量的分流和负载的均衡;数据流是单向的,从master到slave
2.复制的配置
	用命令进行主从复制
		复制:从客户端执行:slaveof 127.0.0.1:6379
		取消复制:从客户端执行:slaveof no one
	修改配置进行主从复制
		slaveof ip port
		slave-read-only yes(主节点只执行读的操作;如果从节点可以写入,那主从数据就不一致了)
	查看从节点连接状态:redis-cli -p 6380 info replication
3.全量复制和部分复制
	全量复制开销:
		1.bgsave时间
		2.RDB文件传输时间
		3.从节点清空数据
		4.从节点加载RDB的时间
		5.可能的AOF重写时间
4.故障处理
	1.size宕机
	2.master宕机
5.开发运维常见问题

Redis Sentinel
1.主从复制高可用
	1.进行数据备份
	2.从节点读取数据,减少主节点压力
	发生问题:一主多从,如果master宕机,需要将一个从节点执行slaveof no one,然后将该节点晋升为主节点,其余从节点去连接这个新的主节点
	这里有几个问题,例如怎么检测master是否宕机,宕机之后需要一个脚本来执行上诉一个过程
	这里就引入了redis sentinel,来进行高可用的实现
2.架构说明
	客户端从redis sentinel获取数据,sentinel来监控主节点和从节点
	sentinel故障转移:
		1.多个sentinel发现并确认master有问题
		2.选举出一个sentinel作为领导
		3.该sentinel选出一个slave作为新的master
		4.通知其余slave成为新的master的slave
		5.通知客户端主从变化
		6.等待老的master复活成为新的master的slave
3.安装配置
	1.配置开启主从节点
	2.配置开启sentinel监控主节点(sentinel是特殊的redis,它不储存数据,只用来监控master)
	3.sentinel详细配置节点
		1.port ${port}	(端口号)
		2.daemonize yes (守护进程方式启动)
		3.dir ""		(日志存储路径)
		4.logfile "${port}.log"		(日志文件名)
		5.sentinel monitor mymaster 127.0.0.1 7000 2 (mymaster: 主节点名 127.0.0.1 7000:主节点的IP和端口号 2:多少个sentinel发现master有问题就执行故障处理)
		6.sentinel down-after-milliseconds mymaster 30000 (主节点超过30000毫秒未响应就认为该master有问题)
		7.sentinel parallel-syncs mymaster 1 (从节点复制新的master是并发还是串行,这里配置为1,代表每次只能复制1个,这样可以减轻master的压力)
		8.sentinel failover-timeout mymaster 180000 (故障转移时间)
		启动命令:redis-sentinel redis-sentinel-26379.conf(sentinel配置文件名称)
4.客户端连接
	1.sentinel地址集合
	2.masterName
	3.不是代理模式
5.实现原理
	sentinel里有三个定时任务:
	1.每10s每个sentinel对master和slave执行info
		1.发现slave节点
		2.确认主从关系
	2.每2s每个sentinel通过master节点的channel交换信息(pub/sub)
		1.通过__sentinel__:hello频道交互
		2.交互对节点的"看法"和	自身信息
	3.每1s每个sentinel对其他sentinel和redis执行ping(心跳检测的过程,失败判定的依据)
6.总结
	Redis sentinel 是Redis的高可用实现方案：
	故障发现,故障自动转移,配置中心,客户端通知
	尽可能在不同物理机上部署Redis sentinel所有节点
	客户端初始化时连接的是sentinel节点集合,不再是具体的redis节点,但sentinel只是配置中心而不是代理
	
Redis Cluster
	1.呼唤集群
		为什么呼唤?
			1.并发量
			2.数据量
	2.数据分布
		1.哈希分布 特点:数据分散度高,键值分布业务无关,无法顺序访问,支持批量操作	典型产品:一致性哈希Memcache,Redis Cluster,其他缓存产品
			1.节点取余分区(hash(key)%nodes)
				客户端分片:哈希+取余
				数据节点关系变化,导致数据迁移
				迁移数量和添加节点数量有关,建议翻倍扩容
			2.一致性哈希分布(一个闭合的环,数据落在这个环上会顺时针去寻找节点)
				客户端分片:哈希+顺时针(优化取余)
				只影响邻近节点,但是还是有数据迁移
				翻倍伸缩:保证最小迁移和负载均衡
			3.虚拟槽分区(redis cluster使用的方式)
				预设管理槽:每个槽映射一个数据子集,一般比节点数大
				良好的哈希函数:例如CRC16
				服务端管理节点,槽,数据
		2.顺序分布 特点:数据分散度易倾斜,键值业务相关,可顺序访问,支持批量操作 典型产品:BigTable Hbase
	3.基本架构
		1.节点	(有多个节点,都会复制读写)
		2.meet	(节点之间的互相通信)
		3.指派槽 (新增节点,指派槽之后才可以进行正常的读写)
		4.复制	(内部实现了高可用,主节点宕机,会有从节点顶上来,不过这里用的不是sentinel)
	4.两种安装
		1.原生命令安装
			1.配置开启节点
				port ${port}
				daemonize yes
				dir ""
				dbfilename "dump-${port}.rdb"
				logfile "${port}.log"
				cluster-enabled yes	(是否为cluster节点)
				cluster-node-timeout 15000 (超时时间)
				cluster-config-file "nodes-${port}.conf" (集群节点的配置)
				cluster-require-full-coverage no (有一个节点出问题,其余节点是否停止服务)
				
				开启redis: redis-server redis-7000.conf
				开启redis: redis-server redis-7001.conf
				开启redis: redis-server redis-7002.conf
			2.meet
				redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 70001 
				redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 70002 
			3.指派槽
				redis-cli -h 127.0.0.1 -p 7000 cluster addslots {0...5461}
				redis-cli -h 127.0.0.2 -p 7000 cluster addslots {5462...10922}
				redis-cli -h 127.0.0.3 -p 7000 cluster addslots {10923...16383}
			4.主从关系的分配(只有分配了主从关系,才可以实现故障自动转移)
				redis-cli -h 127.0.0.3 -p 7003 cluster replicate ${node-id-7000}
		2.官方工具安装(Ruby)
			1.下载 编译 安装 ruby
			2.安装rubygem redis
			3.安装redis-trib.rb
	5.集群伸缩
		原理:槽和数据在节点之间的移动
		扩容集群
			1.准备新节点
			2.加入集群
			3.迁移槽和数据
				1.迁移槽计划
				2.计算槽
				3.迁移数据
		收缩集群
			1.下线迁移槽
			2.忘记节点
			3.关闭节点
			
缓存的使用与设计
	1.缓存的收益与成本
		收益:1.加速读写
			 2.降低后端负载
		成本:1.数据不一致(缓存层和数据层有时间窗口不一致,和更新策略有关)
			 2.代码维护成本
			 3.运维成本
		使用场景:1.降低后端负载
					对高消耗的SQL
				 2.加速请求响应
				 3.大量写合并为批量写
					如计数器先Redis累加再批量写DB
	2.缓存更新策略
		1.LRU(最近未使用的数据)/LFU/FIFO算法剔除:例如maxmemory-policy(最大内存策略,当达到最大内存时)
		2.超时剔除:例如expire
		3.主动更新:开发控制生命周期
		两个建议:
			1.低一致性:最大内存和淘汰策略
			2.高一致性:超时剔除和主动更新结合,最大内存和淘汰策略兜底
	3.缓存粒度控制
		1.通用性:全属性更好
		2.占用空间:部分属性更好
		3.代码维护:表面上全属性更好
	4.缓存穿透优化
		问题描述:客户端请求缓存miss后,会请求DB;正常DB会返回一个结果,写到缓存中,然后返回给客户端;但是如果DB也返回一个空,那么缓存中存入的也是空,下次客户端还是会请求DB
				 如果客户端请求一个根本不存在的key,就会导致这种缓存穿透问题
		产生的原因:1.业务代码有问题
				   2.恶意攻击,爬虫等
		如何发现问题:1.业务的响应时间
				     2.业务本身问题(产品功能出现问题)
					 3.相关指标(总调用数,缓存命中数,存储层命中数)
		解决方法:1.把DB返回的null写到cache中,并设置一个过期时间
				 存在的问题:1.需要更多的键(比如恶意攻击,爬虫等无法预知键值,所以要设置过期时间)
						    2.缓存层和存储层数据"短期"不一致(比如网络或者什么问题请求失败,但是DB有值,这个过期时间就会有短期的数据不一致的问题)
				 2.布隆过滤器(在请求的时候,判断请求是否为有效的,如果无效,直接过滤掉;如果有效,再去请求cache)
	5.无底洞问题优化(批量接口需求mget,mset等)
		问题描述:Facebook在2010年的时候,有3000个memcache,再之后加机器,性能不但没有提升,反而下降了
				这中间多的是机器互相之间的网络通信时间,如mget 原来的时间复杂度为O(1),加机器之后为O(node),node就是机器节点的数量
				更多的机器不代表更高的性能
		解决方法:1.命令本身优化(例如慢查询keys,时间复杂度为O(n)的命令)
				 2.减少网络通信次数
				 3.降低接入成本:例如客户端长连接/连接池等
	6.缓存雪崩优化
		问题描述:缓存在同一时间大量过期,接着来了一大波请求瞬间直接请求了数据库
		解决办法:1.互斥锁
			     2.建立备份缓存(二级缓存),如缓存A和B,A设置超时时间,B不设置超时时间,先从A读,A没有读B,重建A之后也更新B
				 3.缓存加上随机时间长度,比如5分钟的过期时间加上2分钟的随机超时时间
	7.热点Key重建优化
		问题描述:一个大V大了一条动态,有许多查询,这个时候如果缓存过期,在重新查DB->存到cache中这个过程中,可能有许多查询在同时访问DB
		解决方法:1.互斥锁(mutex key)
					在重新查DB->存到cache中这个过程中加一个lock,其他查询就会等待,直到锁被解开
				 2.缓存永不过期
					缓存层面不设置过期时间,逻辑成面设置过期时间
					比如之前 set hello world 现在需要给set设置一个过期时间,新增一个属性如timeout
					当获取热点key的时候,我们先拿到timeout,如果这个时间超过了的时候,使用单独的一个线程,对缓存进行重建
					存在数据不一致的问题,因为它有可能会没等缓存进行重建就拿到了老的结果
					线程无需等待,不会出现死锁的问题
					
布隆过滤器
	问题:现有50个亿电话号码,现有10万个号码,要快速准确判断这些号码是否已经存在
	1.通过数据库查询(实现快速有点难)
	2.存到内存中(50亿*8字节=40GB 内存浪费或不足,这里假设一个电话号码是用长整形)
	类似的问题,垃圾邮件过滤,文字处理软件(例如word)错误单词检测
	实现原理:一个很长的二进制向量和若干个哈希函数
	参数:m个二进制向量,n个预备数据,k个哈希函数